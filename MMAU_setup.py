#!/usr/bin/env python3
import os
import sys
import time
import getpass
import shlex
from pathlib import Path
import shutil


ENV_FILE = Path(__file__).parent / ".env"


def _read_existing_env(filepath: Path) -> dict[str, str]:
    env: dict[str, str] = {}
    if not filepath.exists():
        return env
    for line in filepath.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip()
        # Strip optional export
        if key.startswith("export "):
            key = key[len("export ") :].strip()
        # Remove surrounding quotes if present
        if (value.startswith("'") and value.endswith("'")) or (
            value.startswith('"') and value.endswith('"')
        ):
            value = value[1:-1]
        env[key] = value
    return env


def _input_with_default(prompt: str, default: str | None) -> str:
    if default:
        full_prompt = f"{prompt} [{default}]: "
    else:
        full_prompt = f"{prompt}: "
    resp = input(full_prompt).strip()
    return resp if resp else (default or "")


def _input_secret_with_default(prompt: str, default: str | None) -> str:
    masked = None
    if default:
        # Mask all but last 4 characters
        masked = ("*" * max(0, len(default) - 4)) + default[-4:]
    show = f"{prompt} [{masked}]: " if masked else f"{prompt}: "
    resp = getpass.getpass(show).strip()
    return resp if resp else (default or "")


def _ensure_file_exists(path_str: str) -> str:
    expanded = os.path.abspath(os.path.expanduser(path_str))
    if not os.path.isfile(expanded):
        print(f"Error: File not found at {expanded}", file=sys.stderr)
        return ""
    return expanded


def _write_env_file(values: dict[str, str], filepath: Path) -> None:
    # Backup existing
    if filepath.exists():
        ts = time.strftime("%Y%m%d-%H%M%S")
        backup = filepath.with_suffix(filepath.suffix + f".bak.{ts}")
        backup.write_text(filepath.read_text(encoding="utf-8"), encoding="utf-8")

    lines = [
        f"# Generated by setup.py at {time.strftime('%Y-%m-%d %H:%M:%S')}",
        # Use single-quoted, shell-safe values via shlex.quote
        f"GOOGLE_APPLICATION_CREDENTIALS={shlex.quote(values['GOOGLE_APPLICATION_CREDENTIALS'])}",
        f"VERTEX_AI_PROJECT={shlex.quote(values['VERTEX_AI_PROJECT'])}",
        f"VERTEX_AI_LOCATION={shlex.quote(values['VERTEX_AI_LOCATION'])}",
        f"GRADER_OPENAI_API_KEY={shlex.quote(values['GRADER_OPENAI_API_KEY'])}",
        "",
    ]
    content = "\n".join(lines)
    filepath.write_text(content, encoding="utf-8")
    try:
        os.chmod(filepath, 0o600)
    except OSError:
        # Non-fatal if chmod fails on some filesystems.
        pass


def _copy_filtered_json_files(src_dir: Path, dst_dir: Path) -> list[str]:
    """Copies only .jsonl and .json files from src_dir (recursively) to dst_dir.

    If a filename collision occurs, appends an incrementing suffix.

    Args:
        src_dir: Source directory to scan recursively.
        dst_dir: Destination directory to place filtered files.

    Returns:
        A list of destination file paths copied.
    """
    dst_dir.mkdir(parents=True, exist_ok=True)
    copied: list[str] = []
    for pattern in ("*.jsonl", "*.json"):
        for src_path in src_dir.rglob(pattern):
            if not src_path.is_file():
                continue
            dst_path = dst_dir / src_path.name
            if dst_path.exists():
                stem = dst_path.stem
                suffix = dst_path.suffix
                counter = 1
                while dst_path.exists():
                    dst_path = dst_dir / f"{stem}_{counter}{suffix}"
                    counter += 1
            shutil.copy2(src_path, dst_path)
            copied.append(str(dst_path))
    return copied


def _download_mmau_datasets(target_dir: Path) -> int:
    """Downloads the apple/mmau dataset and filters JSON/JSONL files to target_dir.

    The full snapshot is stored under target_dir / "_raw" and only *.jsonl/*.json
    are copied (flattened) into target_dir.

    Args:
        target_dir: Destination directory (e.g., MMAU_datasets).

    Returns:
        0 on success, non-zero on failure.
    """
    try:
        # Deferred import so running setup without extras still works.
        from huggingface_hub import snapshot_download  # type: ignore
    except Exception as e:  # pylint: disable=broad-except
        print(
            "Error: huggingface_hub is required to download datasets. Install extras with 'pip install \".[mmau]\"' and re-run.",
            file=sys.stderr,
        )
        print(f"Details: {e}", file=sys.stderr)
        return 1

    raw_dir = target_dir / "_raw"
    try:
        raw_dir.parent.mkdir(parents=True, exist_ok=True)
        print("Downloading 'apple/mmau' dataset snapshot. This may take a few minutes...")
        snapshot_download(repo_id="apple/mmau", repo_type="dataset", local_dir=str(raw_dir))
    except Exception as e:  # pylint: disable=broad-except
        print(f"Error downloading dataset: {e}", file=sys.stderr)
        return 2

    try:
        copied = _copy_filtered_json_files(src_dir=raw_dir, dst_dir=target_dir)
        print(f"Copied {len(copied)} JSON/JSONL files into {target_dir}.")
        if len(copied) == 0:
            print(
                "Warning: No .jsonl or .json files were found in the downloaded snapshot.",
                file=sys.stderr,
            )
    except Exception as e:  # pylint: disable=broad-except
        print(f"Error filtering JSON files: {e}", file=sys.stderr)
        return 3
    return 0


def main() -> int:
    print("This script will configure environment variables in a .env file.")
    print("The run_evaluator.sh script will auto-load .env on execution.\n")

    existing = _read_existing_env(ENV_FILE)

    # Defaults from environment override .env defaults
    defaults = {
        "GOOGLE_APPLICATION_CREDENTIALS": os.environ.get(
            "GOOGLE_APPLICATION_CREDENTIALS", existing.get("GOOGLE_APPLICATION_CREDENTIALS", "")
        ),
        "VERTEX_AI_PROJECT": os.environ.get(
            "VERTEX_AI_PROJECT", existing.get("VERTEX_AI_PROJECT", "")
        ),
        "VERTEX_AI_LOCATION": os.environ.get(
            "VERTEX_AI_LOCATION", existing.get("VERTEX_AI_LOCATION", "")
        ),
        "GRADER_OPENAI_API_KEY": os.environ.get(
            "GRADER_OPENAI_API_KEY", existing.get("GRADER_OPENAI_API_KEY", "")
        ),
    }

    # GOOGLE_APPLICATION_CREDENTIALS (must exist)
    cred_path = ""
    while not cred_path:
        raw = _input_with_default(
            "Path to GOOGLE_APPLICATION_CREDENTIALS JSON",
            defaults["GOOGLE_APPLICATION_CREDENTIALS"],
        )
        checked = _ensure_file_exists(raw)
        if checked:
            cred_path = checked

    # VERTEX_AI_PROJECT
    project = ""
    while not project:
        project = _input_with_default("VERTEX_AI_PROJECT", defaults["VERTEX_AI_PROJECT"]).strip()
        if not project:
            print("Error: VERTEX_AI_PROJECT cannot be empty.", file=sys.stderr)

    # VERTEX_AI_LOCATION
    location = ""
    while not location:
        location = _input_with_default("VERTEX_AI_LOCATION", defaults["VERTEX_AI_LOCATION"]).strip()
        if not location:
            print("Error: VERTEX_AI_LOCATION cannot be empty.", file=sys.stderr)

    # GRADER_OPENAI_API_KEY (secret)
    api_key = ""
    while not api_key:
        api_key = _input_secret_with_default(
            "GRADER_OPENAI_API_KEY", defaults["GRADER_OPENAI_API_KEY"]
        ).strip()
        if not api_key:
            print("Error: GRADER_OPENAI_API_KEY cannot be empty.", file=sys.stderr)

    values = {
        "GOOGLE_APPLICATION_CREDENTIALS": cred_path,
        "VERTEX_AI_PROJECT": project,
        "VERTEX_AI_LOCATION": location,
        "GRADER_OPENAI_API_KEY": api_key,
    }
    _write_env_file(values, ENV_FILE)

    print(f"\nSaved configuration to {ENV_FILE}.")

    # Optionally download MMAU datasets into MMAU_datasets.
    # - If '--download-mmau' flag is present, download without prompting.
    # - Otherwise, prompt the user interactively.
    want_download = False
    if "--download-mmau" in sys.argv:
        want_download = True
    else:
        try:
            ans = _input_with_default(
                "Download MMAU datasets to MMAU_datasets now? (y/N)", "N"
            )
            want_download = ans.strip().lower() in {"y", "yes"}
        except (EOFError, KeyboardInterrupt):
            want_download = False

    if want_download:
        target_dir = Path.cwd() / "MMAU_datasets"
        rc = _download_mmau_datasets(target_dir)
        if rc != 0:
            return rc
        # Print a helpful note about typical files.
        print(
            "\nDownloaded files are available under MMAU_datasets/. Typical names include:")
        print("Raw snapshot kept under MMAU_datasets/_raw.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


